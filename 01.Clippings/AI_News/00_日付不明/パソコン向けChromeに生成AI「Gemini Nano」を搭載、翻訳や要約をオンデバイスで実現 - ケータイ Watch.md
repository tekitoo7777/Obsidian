# パソコン向けChromeに生成AI「Gemini Nano」を搭載、翻訳や要約をオンデバイスで実現 - ケータイ Watch

作成日: 2025-05-19 19:24:33

## プロパティ

- タグ: 生成AI, Gemini Nano, Chrome, 翻訳, 要約, オンデバイスAI, Webサイト, AIモデル, ローカル, プライバシー, インターネット回線, ai, 記事, google, タスク管理, マネジメント
- 日付: 2024-05-15
- リンク: https://k-tai.watch.impress.co.jp/docs/news/1591509.html

グーグルは、デスクトップ向けの「Chrome」のバージョン126に、「Gemini Nano」を組み込みする。主に、AIを使って閲覧中のWebサイトの翻訳や、要約などが行いやすくなる。「Chrome 126」に「Gemini Nano」を組み込み![image_20250519_192433.png](../assets/image_20250519_192433.png)
グーグルが公開したデモでは、ブログサービス「アメーバブログ」の記事作成画面で作成した記事に「タイトルを生成する（Generate blog title）」ボタンが追加され、記事のタイトルが生成AIによって自動生成されている。AIによって生成されたタイトルの候補![image_20250519_192433.png](../assets/image_20250519_192433.png)
候補から選んでタイトルを決定![image_20250519_192433.png](../assets/image_20250519_192433.png)
## オンデバイスAIのメリット
サーバサイドで実行される生成AIは、大規模なモデルにおいては最適な選択肢だが、オンデバイスやハイブリッド式にもそれぞれメリットがある。たとえば、生成AIは最小のモデルでも、平均的なWebページの1000倍ほどの大きさがあり、なおかつWebサイト間でモデルを共有できないため、ページロード毎にダウンロードすることは非現実的と言える。一方で、ローカルで実行できる「Gemini Nano」を使うと、WebサイトやWebアプリケーションが、独自のAIモデルを展開または管理せずに、生成AIを利用したタスクを実行できるようになる。Chromeに組み込みされる「Gemini Nano」には、基本モデルとエキスパートモデルがあり、エキスパートモデルは特定の用途にあわせて、より高いパフォーマンスと品質を実現する。たとえば、翻訳APIはコンテンツの翻訳に特化したエキスパートモデルであり、エキスパートモデルはハードウェアの必要要件が低く抑えられる傾向がある。ビルトイン式のAIモデルでは、Webブラウザ（Chrome）がモデルを配信するにあたり、デバイスのスペックを考慮し、モデルの更新を管理するため、オンデバイスAIと比較して導入が容易という。このほか、ビルトイン式のAIモデルでは、機密データーをローカルで処理でき、プライバシー面でのリスクが低い。また、インターネット回線が使えない状態でもAIが利用でき、通信待ち時間が短縮され、快適なユーザー体験が得られるという。これに対して、ハイブリッド式またはサーバーサイドでのAI利用は、より大きなモデルを使ったり、広範囲のプラットフォームやデバイスで生成AIを利用する場合に利便性が高い。
Googleはデスクトップ向けChromeバージョン126にAI「Gemini Nano」を組み込むことで、Webサイトの翻訳や要約を容易に行えるようにする。Gemini Nanoはローカルで実行可能で、WebサイトやWebアプリケーションが独自のAIモデルを展開または管理せずに、生成AIを利用したタスクを実行できる。また、機密データをローカルで処理でき、プライバシーリスクが低く、インターネット回線が使えない状況でもAIが利用可能である。